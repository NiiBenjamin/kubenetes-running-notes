Kubernetes:
Containerization --> Docker, Rocket(Rkt),Container-d
   Containerization involves writing/modifying Dockerfiles and using those files
   to create images and shipping the images to image registries.  
   From the registries these images can be distributed to any  environment.  

  We could also use Containerization softwares like Docker to deploy and manage Containers

Container Orchestration Tools --> 
   Docker Swarm,
   Kubernetes,
   OpenShift

Kubernetes:
  10 years 
  July 2015  --- 2023  = 8years  

chartGPT started in 2023.     


kubernetes architecture:
controlPlane/MasterNodes:
  apiServer
  etcd  
  scheduler  
  controllerManagers   
workerNodes:
  kubelet   
  container runtime [Container-d]
  kube-proxy

kubernetes-client:
  kubectl  
      kubectl create/delete/get/describe/apply/run/expose 
      kubeconfig [.kube/config ] file will authenticate the admin  
                                 the caller admin/Developer/Engineer  
  ui  
  api  

 docker run/build  pull push 


kubernetes: 
   cluster:
   nodes:  
   pods:  
   containers :  

cluster ---> nodes ---> pods  ---> containers  :

kubernetes security - RBAC:
  Developers [ Paul, Joyce, Chidi ] 
  Engineers  [ James, Dominion, Janet ] 

authentication via kubeconfig : 
authorisation via RBAC:

Installation:
============
Local K8s Cluster(Single Node K8s Cluster)
------------------------------------------
   minikube
       choco install minikube  = windows   
       brew install minikube   = macOS  
       minikube start  
   Kind   = 
   Docker Desktop 
      https://docs.docker.com/desktop/kubernetes/
  POC = 

Multi Node Kubernetes Clusters:
================================
1. Self Managed Kubernetes [k8s] Cluster = IaaS--EC2  :
    kubeadm --> We can setup multi node k8's cluster using kubeadm.
    kubespray --> We can setup multi node k8s cluster using kubespray
     (Ansbile Playbooks Used internally by kubespray).

WITH  Self Managed Kubernetes [k8s] Cluster both the    
     controlPlane [apiServer, etcd, scheduler, Controller Managers] 
      and 
     workerNodes [  kubelet, containerRuntime-Container-d, kube-proxy]  
  
  are managed by the Admin/Kubernetes/DevOps Engineers

2. Managed k8s Cluster  (Cloud Services) = PaaS  : 
   The controlPlane is managed by a cloud provider or third party.  
   The controlPlane and all it components are managed by the Cloud provider 
   EKS --> Elastic Kubernetes Service(AWS)
   AKS --> Azure Kubernetes Service(Azure)
   GKE --> Google Kubernetes Engine(GCP)
   IKE --> IBM K8s Engine(IBM Cloud)

Kubernetes Cluster = k8s  

3. KOPS: is a software use to create production GRADE/ready k8s in AWS and  
         azure for the kops beta version  
         It creates a highly available kubernetes services in Cloud like AWS.
            KOPS will leverage Cloud Sevices like:
              vpc, 
              AutoScaling Groups, 
              LoadBalancer, 
              Launch Template/configuration
              ec2-instances nodes [workerNodes and masterNodes]  

   kops create cluster --name mycluster --az us-east-2b nodes-4 master 3    

    iam role/user  

Rancher: - Using Rancher we can deploy both managed and self managed k8s
           Rancher serves as a glass to access and manage multiple k8s  
           from the dashboard [UI]  - rancher dashboard 
           authentication and authorisation: EKS/AKS/GKE/IKE 

Ticket 001:
  Setup a multi nodes self Managed kubernetes cluster using kubeadm.
  requirements -- 
1. check the kubernetes official documentation  
https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

2. check the company's documentation for kubeadm setup  
https://github.com/LandmakTechnology/package-management/blob/master/kubeadm/READme.md

kubeadm join 172.0.0.11:6443 --token a6hasz.8gav6h5wjy1jy4ca --discovery-token-ca-cert-hash sha256:da32d4d637fa0f9769cd21b90273ba796fb09fb0be08e16a795a68a55bb9846f

docker resources/objects use to deploy applications:
  Dockerfiles/images/networks/volumes/docker-compose.yml/etc.  

ticket002
========
Deploy workloads in kubernetes;

kubernetes resources/objects used to deploy application includes:
kubernetes Orchestrate and managed containerised Applications  
This applications run as containers  
These containers are housed in pods  
Pods are housed in nodes    
nodes are housed in the cluster   

kubernetes resources/objects used to deploy application include is:
    Pod or    :
    controllerManagers:
      Replication Controller
      ReplicaSet
      DaemonSet
      StatefulSets
      Deployment
      Volume
      Job       

Exposing/accessing applications = Service Discovery:
    Service Types:
    ClusterIP
    NodePort
    LoadBalancer
    ExternalName  
  ingress 
  networkPolicy 

Namespace:
  It is a virtual cluster inside your cluster 
  [ dev / uat / prod ], [sales, accounts, cs, payroll]
  pros:
    isolation  
    permissions 
       dev  - Developers
       prod - Engineers
    resource utilisation  
       dev  - cpu=5Gi mem=1000Mi 
       prod - cpu=25Gi mem=8000Mi 
    performance
       High priority   

RBAC - Security:
  NameSpace
  Role   = dev [list/read]
  RoleBinding  
         Users  
         groups  
         ServiceAccounts  
  ClusterRole  
  ClusterRoleBinding
  ServiceAccounts  

Namespace:
  fintech / 
  ecommerce 

kubernetes uses the kubectl client or the UI to run workloads.
  kubectl get namespace
  kubectl get ns

ubuntu@master:~$ kubectl get ns
NAME              STATUS   AGE
default           Active   41m
kube-node-lease   Active   41m
kube-public       Active   41m
kube-system       Active   41m

ubuntu@master:~$ kubectl get nodes
NAME     STATUS   ROLES           AGE   VERSION
master   Ready    control-plane   42m   v1.27.4
node1    Ready    <none>          37m   v1.27.4
node2    Ready    <none>          25m   v1.27.4
ubuntu@master:~$
ubuntu@master:~$ kubectl get pod -A
NAMESPACE     NAME                             READY   STATUS    RESTARTS      AGE
kube-system   coredns-5d78c9869d-26tvd         1/1     Running   0             42m
kube-system   coredns-5d78c9869d-s7ml5         1/1     Running   0             42m
kube-system   etcd-master                      1/1     Running   0             42m
kube-system   kube-apiserver-master            1/1     Running   0             42m
kube-system   kube-controller-manager-master   1/1     Running   0             42m
kube-system   kube-proxy-5n22s                 1/1     Running   0             37m
kube-system   kube-proxy-f8f4m                 1/1     Running   0             25m
kube-system   kube-proxy-jxt5x                 1/1     Running   0             42m
kube-system   kube-scheduler-master            1/1     Running   0             42m
kube-system   weave-net-5zvgj                  2/2     Running   1 (41m ago)   41m
kube-system   weave-net-8wtjl                  2/2     Running   0             37m
kube-system   weave-net-wb844                  2/2     Running   0             25m
ubuntu@master:~$

https://kubernetes.io/docs/setup/best-practices/cluster-large/
   No more than 110 pods per node
   No more than 5,000 nodes
   No more than 150,000 total pods
   No more than 300,000 total containers

kubectl get namespaces
kubectl get ns   

-#Create Name Space Using Imperative Command
    kubectl create namespace <nameSpaceName>
    kubectl create namespace dev  

-declarive approach
-# Using Declarative Manifest file 

apiVersion: v1   
kind: Namespace      
metadata:
  name: prod 
================

PODS:
====
POD --> Pod is the smallest building block which we can deploy applications in k8s.
Pod represents running process. Pod can contains one or more containers.
These container will share same network, storage and any other specifications.
Pod will have unique IP Address in k8s cluster. 

Pods
 SingleContainerPods --> Pod will have only one container.       98%
 
 MultiContainerPods(SideCar) --> POD with two or more containers. 2%  
         application Container  
         SideCar containers:
         logMgt  container  
         utility Container [ Truck = ]

How to deploy run/execute tasks/workloads in kubernetes??
   1. Imperative  approach 
        By using commands 

   2. Declarative approach
        By using files [manifests files]  

-# Create POD Using Command
kubectl run <podName> --image=<imageName> --port=<containerPort> -n <namespaceName>
kubectl run hello --image=mylandmarktech/hello --port=80 -n dev  

Docker images = dockerHub other registries:
-- python-web-app
   nodeweb-app 
   net-webapp 
   mylandmarktech/hello
   nginx 
   mysql  
   mongo  
   jenkins  
   sonarqube  
   nexus 


Use the declarive approach to deploy workloads in kubernetes:
  Manifest files = kams 
Manifest files are written in yaml/yml language 

key:values pairs:  
  name: simon  
dictionary: number of key:values pairs:    
   name: simon   
   age: 50  
   sex: male  
list:
   students:
      - name: paul  
        age: 55  
        sex: male  
      - name: juliet
        age: 65 
        sex: female         

pod.yml template
======
apiVersion: v1    
kind: Pod     
metadata:
  name: <podName>
  namespace: <namespaceName>
  lables:
    key: <value> 
    key: <value> 
spec:
  containers:
  - name: containerName   
    image: imageName  
    ports:
    - containerPort: podNumber  

pod.yml   = kams   
======
kind: Pod    
apiVersion: v1    
metadata:
  name: webapp    
  namespace: dev    
  labels:
    app: webapp   
    tier: fe    
spec:
   containers:
   - name: web   
     image: mylandmarktech/maven-web-app 
     ports:
     - containerPort: 8080  

kubectl config set-context --current --namespace=dev

kubectl get all
kubectl get events
kubectl delete all --all 
kubectl delete all --all -n dev     
kubectl delete pod --all
kubectl get pods 
kubectl get pods -o yaml  
kubectl get pods --show-labels
kubectl get pods -o wide
kubectl get pods -o wide --show-labels

kubectl  describe pod <podName>
kubectl  describe pod <podName> -n <namespace>


kubeadm reset  
sudo hostnamectl set-hostname master
kubectl init    
-#Generate the master join token on the master node
kubeadm token create --print-join-command

==================================================================================================================================================================



pod.yml   = kams   
======
kind: Pod    
apiVersion: v1    
metadata:
  name: webapp    
  namespace: dev    
  labels:
    app: webapp   
    tier: fe    
spec:
   containers:
   - name: web   
     image: mylandmarktech/maven-web-app 
     ports:
     - containerPort: 8080  

kubectl config set-context --current --namespace=dev

kubectl get all
kubectl get events
kubectl delete all --all 
kubectl delete all --all -n dev     
kubectl delete pod --all
kubectl get pods 
kubectl get pods -o yaml  
kubectl get pods --show-labels
kubectl get pods -o wide
kubectl get pods -o wide --show-labels

kubectl  describe pod <podName>
kubectl  describe pod <podName> -n <namespace>


kubeadm reset  
sudo hostnamectl set-hostname master
kubectl init    
-#Generate the master join token on the master node
kubeadm token create --print-join-command

ubuntu@master:~$ kubectl get pods --show-labels
NAME     READY   STATUS    RESTARTS   AGE    LABELS
hello    1/1     Running   0          4d1h   run=hello
webapp   1/1     Running   0          4d1h   app=webapp,tier=fe

kubectl run hello --image=mylandmarktech/hello --port=80 -n dev  

ServiceDicovery:
===============
ClusterIP is the default kubernetes service type that support communication  
within the cluster.  
kams  
service.yml  -- kams   
===========
hello-appSVC.yml    
kind: Service  
apiVersion: v1     
metadata:
   name: hellosvc  
spec:
   type: ClusterIP  
   selector:
      run: hello  
   ports:
   - port: 80    
     targetPort: 80     
---  
kind: Service  
apiVersion: v1     
metadata:
   name: webappsvc  
spec:
   type: NodePort    
   selector:
      app: webapp  
   ports:
   - port: 80    
     targetPort: 8080   
     nodePort: 31000 [30000 - 32676]   


kubectl get svc -n <namespace>
kubectl describe svc  
kubectl get ep  
kubectl describe svc   
kubectl delete svc   

kubernetes Service:
  In Kubernetes Service makes our pods accessible/discoverable 
  within the cluster or exposing them outside  the cluster.
  service will identify pods using it's labels And Selector. 
  Whenever we create a service a ClusterIP (virtual IP) Address 
  will be allocated for that serivce and DNS entry will be created for that IP.
  So internally we can access using service name(DNS).

 helloappsvc ----> helloapp  


What is FQDN?
Fully Qualified Domain name. 
If one POD need to access service & which are in different names space 
we have to use FQDN of the service.
Syntax: <serivceName>.<namespace>.svc.cluster.local
ex: myappsvc.dev.svc.cluster.local

ubuntu@master:~$ kubectl get svc -o wide
NAME        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR
hellosvc    ClusterIP   10.101.221.91   <none>        80/TCP         12m   run=hello
webappsvc   NodePort    10.111.41.117   <none>        80:31000/TCP   12m   app=webapp

serviceNAME  = hellosvc   
service FQDN = hellosvc.dev.svc.cluster.local

curl hellosvc.dev.svc.cluster.local  

For pods to be recraete the must be managed/controlled by:
   1. ControllerManagers  
   2. kubelet SERVICE - manages & maintained the state of static pods  

IQ: what is Static Pods ?
    Static Pods are controlled by the kubelet service  


sudo vi /etc/kubernetes/manifests/file.yml  
kams  
kind: Pod    
apiVersion: v1   
metadata: 
   name: myapp 
spec:   
   containers:
      - name: myapp   
        image: mylandmarktech/java-web-app   
        ports:
        - containerPort: 8080  

NB:
We should not create pods directly to deploy applications.
If a node  goes down in which pods are running, Pods will not be rescheduled.
We have to create pods with help of controllers which manages POD life cycle.

controllerManagers:
  ReplicationControllers 
  ReplicaSets, 
  Deployments, 
  DaemonSets  

A workload is an application running on Kubernetes consisting of a single component 
or several components that work together inside a set of pods. 
In Kubernetes, a Pod represents a set of running containers on your cluster.

Kubernetes pods have a defined lifecycle. 
For example, once a pod is running in your 
cluster and the node hosting the pod fails then pods running on the node will fail. 
Kubernetes treats that level of failure as final. 
You would need to create a new Pod to recover,even if the node later becomes healthy.

ReplicationControllers = rc 
==========================   = kams     
kind: ReplicationController  
apiVersion: v1    
metadata: 
  name: apprc  
  namespace: dev  
  labels: 
    app: fe     
spec:
   selector:
      app: webapp  
   replicas: 2
   template: podTemplate
     metadata:
       name: app  
       labels:
         app: webapp     
     spec:
       containers:
       - name: web
         image: mylandmarktech/hello 
         ports:
         - containerPort: 80   


labels:    app: webapp   = address: gra  
selectors: app: webapp   = address: gra  

kubectl apply -f <filename.yml>
kubectl apply -f rc.yml
kubectl get rc 
kubectl get rc -n <namespace>
kubectl get all
kubectl scale rc <rcName> --replicas <noOfReplicas>
kubectl scale rc apprc --replicas 4  

kubectl describe rc <rcName>
kubectl delete rc <rcName>

 curl 34.219.16.213:30000

kubectl scale pod app --replicas 4 
kubectl scale rc apprc --replicas 1
kubectl scale rc apprc --replicas 4  
kubectl delete rc apprc

  90:10PM

ReplicaSet = RS :
==========
What is difference b/w replicaset and replication controller?

RS is the next generation of replication controll The only difference as now is
the selector support.

RC --> Supports only equality based selectors.
key == value(Equal Condition)
selector:
    app: javawebapp
    tier: fe    
    client: tesla  

RS --> Supports eqaulity based selectors and also set based selectors.  
eqaulity based:
key == value(Equal Condition)  
set based:
  key in [ value1, value2, value3 ]

selector:
   matchLabels:   -# Equality Based
    key: value
    app: javawebapp
    tier: fe    
    client: tesla

   matchExpressions: -# Set Based
   - key: app
     operator: in
     values:
     - javawebpp
     - myapp  
     - fe  

rs.yml  = kams 
--------------
kind: ReplicaSet
apiVersion: apps/v1  
metadata : 
   name: rsName  
spec:
   replicas: noOfReplicas  
   selector:
      matchLabels:
         <key>: <value>
         <app>: myapp  
      matchExpressions:
      - key: <key>
        operator: <in / not in>
        values:
        - <value1>
        - <value2>
        - <value3>
   template:
     metadata:
       name: podName
       labels:
         <key1>: <value1>
         <key2>: <value2>     
     spec:  
       containers: 
       - name: <containerName>
         image: <imageName:tag>
         ports:
         - containerPort: containerPortNumber  
---
kind: ReplicaSet
apiVersion: apps/v1   
metadata:
  name: webrs  
spec:
  selector: 
    matchLabels:
      app: web 
  replicas: 2   
  template:
    metadata:
      name: webapp  
      labels:
        app: web  
    spec:
      containers:
      - name: web 
        image: mylandmarktech/python-flask-app:2    
        ports:
        - containerPort: 5000      

nodes.yml  
==========
kind: ReplicaSet
apiVersion: apps/v1  
metadata:
   name: noders  
spec:
   replicas: 1 
   selector:
      matchLabels:
         app: node   
   template:
      metadata:
        name: nodeapp  
        labels:
          app: node   
      spec:
         imagePullSecrets:
         - name: dockerhublogin
         containers:  
         - name: nodeapp   
           image: mylandmarktech/nodejs-fe-app  
           ports:
           - containerPort: 9981   
---
kind: Service
apiVersion: v1  
metadata:
  name: nodesvc  
spec:
  type: NodePort  
  selector:
    app: node 
  ports:
  - targetPort: 9981
    ports: 80 
    nodePort: 31500

kubectl create secret docker-registry regcred
 --docker-server=<your-registry-server> 
 --docker-username=<your-name> 
 --docker-password=<your-pword>
 --docker-email=<your-email>


kubectl create secret docker-registry dockerhublogin \
    --docker-server=docker.io --docker-username=mylandmarktech \
    --docker-password=admin123  

apiVersion: v1
kind: Pod
metadata:
  name: private-reg
spec:
  containers:
  - name: private-reg-container
    image: <your-private-image>
  imagePullSecrets:
  - name: regcred


kubectl get rs 
kubectl get rs -n <namespace>
kubectl get all
kubectl scale rs <rsName> --replicas <noOfReplicas>

kubectl describe rs <rsName>
kubectl delete rs <rsName>

kubectl scale rs nodeapp --replicas 3 

  landmarktechnologies

   http://34.219.16.213:31500/landmarktechnologies

    http://34.219.16.213:32000

DaemonSet:
==========
https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/
4 nodes  =    


- pod short lifecycle is = how   
  imagePullBackup error - causes:
    - authentication required for private registry   
    - wrong image registry  
        mylandmarktech/hello  --- mylandmarktech/helo  
    - wrong image tag =  mylandmarktech/hello:5  mylandmarktech/hello:55    
  How to add secrets -- 


ports:
   nodePort that ranges from 30000 - 32676  
   servicePort = port = 80  
   containerPort = 80 = targetPort=80  

   nodePort  vs NodePort service 

kams 

kind: ReplicaSet 
apiVersion: apps/v1   
metadata:
  name: myrs    
spec: 
   selector:
      matchLabels:
         app: be     
   template:
      metadata:
         name: app  
         labels:
            app: be  
      spec:
         imagePullSecrets:
         - name: logindocker  
         containers:
         - name: javawebapp  
           image: mylandmarktech/java-web-app   
           ports:
           - containerPort: 8080 

kubectl create secret docker-registry logindocker \
    --docker-server=docker.io --docker-username=mylandmarktech \
    --docker-password=admin@123 

=========================================

DaemonSet:
==========
https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/
4 nodes  =    

ds.yml  = kams 
-=====--------
kind: DaemonSet    
apiVersion: apps/v1    
metadata:
  name: <RSName> 
  labels:
    <key>: <value> 
spec:
  selector:
    matchLabels:
      <key>: value           
    matchExpressions:
    - key: <key>
      operator: <in /not in>  
      values: 
      - <value1> 
      - <value3>      
  template:
    metadata:
      name: podName  
    labels:
      <key>: <vales>  
    spec:
      containers:
      - name: containerName

hello_ds.yml   
================
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: logmgt
spec:
  selector:
    matchLabels:
      app: hello
  template:
    metadata:
      name: hello
      labels:
        app: hello
    spec:
      containers:
      - name: hello
        image: mylandmarktech/hello
        ports:
        - containerPort: 80

k8s--->nodes--->pods---->Containers:
  How can we deploy containerised applications in k8s?
  We use kubernetes objects to deploy workloads in kubernetes:
  1. Pods --- 
        scaling is not supported  
        lifecycle is very short  
        lacks self-healing capacities
    controllerManagers:
  2. ReplicationControllers  
       kubectl scale rc/rs/deploy  
  3. ReplicaSets
  4. DaemonSets
  5. Deployment  
  6. StatefulSets 

1. Deploy an application which must have a pod running in each = ds  
     logMgt / logshipper  
2. Deploy an application with scaling capacities = rc/rs/Deployment/sts  
3. Deploy an application with scaling capacities = pod  

Master node is tainted / taint  
=============================  
  -- recommissioning / upgrades / updates / patching  


node1    Ready 

kubectl taint nodes node1 key1=value1:NoSchedule

hello-ds.yml  
===========
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: logmgt
spec:
  selector:
    matchLabels:
      app: hello
  template:
    metadata:
      name: hello
      labels:
        app: hello
    spec:
      tolerations:
      - operator: Exists
        effect: "NoSchedule"
      containers:
      - name: hello
        image: mylandmarktech/hello
        ports:
        - containerPort: 80

Master node is tainted / taint  
=============================  
  -- recommissioning / upgrades / updates / patching  

kubectl taint nodes node1 key1=value1:NoSchedule     [taint the node]
kubectl taint nodes node1 key1=value1:NoSchedule-   [untaint the node]

sudo vi /etc/kubernetes/manifests/

imperative  
declarative

kubectl apply -f rc.yml 

kubectl apply -f <ds-filename.yml>
kubectl get ds 
kubectl get ds -n <namespace>
kubectl get all

kubectl describe ds <dsName>
kubectl delete ds <dsName>

kubectl get/describe/delete/edit/apply/  

==============================================


Deployments  
==========
  Advantages:
     Deploy rolout a a RS.
     Updates pods (PodTemplateSpec).
     Rollback to older Deployment versions.
     Scale Deployment up or down.
     Pause and resume the Deployment.
     Use the status of the Deployment to determine state of replicas.
     Clean up older RS that you don’t need anymore.

kubectl apply deploy-app.yml :
  rollout a ReplicaSet  

---
kind: Deployment   
apiVersion: apps/v1    
metadata:
  name: <deploymentName> 
  labels:
    <key>: <value> 
spec:
  strategy:
    rollingUpdates   
    recreate  
  selector:
    matchLabels:
      <key>: value           
    matchExpressions:
    - key: <key>
      operator: <in /not in>  
      values: 
      - <value1> 
      - <value3>      
  template:
    metadata:
      name: podName  
    labels:
      <key>: <vales>  
    spec:
      containers:
      - name: containerName
---
---
app.yml  - kams
------
kind: Deployment
apiVersion: apps/v1  
metadata:
  name:  webapp 
  namespace: dev    
  labels:
    app: be  
spec: 
  replicas: 1     
  selector:
    matchLabels:
      app: web  
  template:
    metadata:
      name: webapp 
      labels: 
        app: web  
    spec: 
      containers:
      - name: webappc
        image: mylandmarktech/maven-web-app  
        ports:
        - containerPort: 8080  

webappsvc.yml  
-------------
kind: Service  
apiVersion: v1  
metadata:
  name: webappsvc  
spec:
  selector:
    app: web  
  type: NodePort 
  ports:
  - port: 80 
    targetPort: 8080
    nodePort: 31000 #[30000-32676]  


44.192.109.203:31000/maven-web-app  

curl 44.192.109.203:31000/java-web-app  


-# Deployment ReCreate
---------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello 
spec:
  replicas: 2
  selector:
    matchLabels:
      app: hello 
  strategy:
    type: Recreate    
  template:
    metadata:
      name: hello
      labels:
        app: hello  
    spec:
      containers:
      - name: helloworld    
        image: 
        ports:
        - containerPort: 80   

hello-svc.yml  
-------------
kind: Service  
apiVersion: v1  
metadata:
  name: hellosvc  
spec:
  selector:
    app: hello   
  type: NodePort 
  ports:
  - port: 80 
    targetPort: 80
    nodePort: 32000 #[30000-32676]  

44.192.109.203:32000 

Update Deployment Image using command 
--------------------------------------
kubectl set image deployment <deploymentName> <containerName>=<imageNameWithVersion> --record

kubectl set image deployment hello mylandmarktech/hello:1 --record  

kubectl rollout status deployment <deploymentName>
kubectl rollout history  deployment <deploymentName>
kubectl rollout history  deployment <deploymentName> --revision 1  
kubectl rollout undo  deployment <deploymentName> --to-revision=1  
kubectl scale deployment <deploymentName> --replicas <noOfReplicas>

kubectl rollout history deployment hello --revision 1    

mylandmarktech.com/success 


ReCreate strategy  --- 
   It comes with downtime  

RollingUpdates strategy
   no downtime 

-# Deployments  Rolling Update

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 4
  strategy:
    type: RollingUpdate
    rollingUpdate:
       maxSurge: 1
       maxUnavailable: 1
  minReadySeconds: 30   
  selector:
    matchLabels:
      app: myapp 
  template:
    metadata:
      name: myapp
      labels:
        app: myapp  
    spec:
      containers:
      - name: myappc  
        image: mylandmarktech/maven-web-app:29 
        ports:
        - containerPort: 80 

https://github.com/LandmakTechnology/kubernetes-manifests

Blue Green deployment Technique : 
Canary deployment Technique : 
  youth 
  adults  
Lagos  / Douala / Accra / Dallas / London  

  users--ROW                               = 75% of traffic 
  users--Lagos[ newApplication version ]   = 25% 

Resource, requests and limits:
--------------------------

eqaulity based selectors:
  ReplicationControllers  
    key:values   
    app: myapp  
Set based selectors:
  Deployments  
  ReplicaSets  
  DaemonSets 
  StatefulSets  
  NodeSelectors 
  NodeAffinity  
key: app 
value in:
  - javawebpp  
  - myapp 

kubernetes.io     

 Deployments  :
    strategy [ReCreate and RollingUpdates]
    techniques [Blue/Green, Canary]


Resource, requests and limits:
--------------------------

eqaulity based selectors:
  ReplicationControllers  
    key:values   
    app: myapp  
Set based selectors:
  Deployments  
  ReplicaSets  
  DaemonSets 
  StatefulSets  
  NodeSelectors 
  NodeAffinity  
key: app 
value in:
  - javawebpp  
  - myapp 

kubernetes.io     

Hello Engineers,

Date: August 5, 2023,

Please watch and practice the video above for today's class. 
The video is tagged;
   kubernetes 5 & 6  = DeamonSets & Deployment1 — May 15, 2023

Thanks. 

Reconnect at 11:30am after watching the video for questions and answer session:
====================================================   


kubernetes objects are used to run workloads or deploy apps.:
Examples of objects:
===================
Pods / 
ReplicationControllers / 
replicasets
DaemonSet  
Deployments 
statefulsets
secrets   
configMaps  
Volumes:
   Persistent Volumes   
   Storage Classes 
   Persistent Volumes Claims

Kubernetes objects used to expose/discover applications:
or kubernetes ServiceDicovery objects:
   ClusterIP   
   NodePort  
   LoadBalancer
   ExternalName   
   ingress 
   networkPolicy

Ticket0045:
=========
Write a simple deployment manifest file
kams
========
kind: Deployment  
apiVersion: apps/v1    
metadata: 
   name: myappdeployment      
spec: 
   selector:
      matchLabels:
         app: myapp
   template:
      metadata:
         name: app  
         labels:
            app: myapp 
      spec:
         containers:
         - name: app
           image: mylandmarktech/hello:2     
           ports:
           - containerPort: 80 

what is the default deployment strategy in kubernetes??
RollingUpdates is the default deployment strategy in kubernetes

what is the default deployment strategy in kubernetes??


kubectl api-resources
kubectl api-resources  | grep -i Deployment 

====================================================
Pods / 
ReplicationControllers / 
replicasets
DaemonSet  
Deployments 
statefulsets

stateless applications

Deployments:
   Create ReplicaSets   
   Create Pods 
   RollOut   = 
   Rollback  
   pause deployment   
replicasets

Manifest-files:
==============
kind: Pod  
apiVersion: v1   
metadata:  
   name: app32
   namespace: dev    
   labels:
      tier: fe  
spec:
   containers:
   - name: app 
     image: mylandmarktech/hello   
     ports: 
     - containerPort: 80 

kind: ReplicationController    
apiVersion: v1   
metadata:  
   name: app32
   namespace: dev    
   labels:
      tier: fe  
spec:
   selector:
      app: web  
   template:
      metadata:
         name: app 
         labels:
            app: web  
      spec:
         containers:
         - name: app 
           image: mylandmarktech/hello   
           ports: 
           - containerPort: 80 


kind: ReplicaSet    
apiVersion: apps/v1   
metadata:  
   name: app32
   namespace: dev    
   labels:
      tier: fe  
spec:
   replicas: 3
   selector:
      matchLabels:
         app: web
   template:
      metadata:
         name: app 
         labels:
            app: web  
      spec:
         containers:
         - name: app 
           image: mylandmarktech/hello   
           ports: 
           - containerPort: 80 
---
kind: DaemonSet    
apiVersion: apps/v1   
metadata:  
   name: app32
   namespace: dev    
   labels:
      tier: fe  
spec:
   selector:
      matchLabels:
         app: web
   template:
      metadata:
         name: app 
         labels:
            app: web  
      spec:
         containers:
         - name: app 
           image: mylandmarktech/hello   
           ports: 
           - containerPort: 80 
---
kind: ReplicaSet    
apiVersion: apps/v1   
metadata:  
   name: app32
   namespace: dev    
   labels:
      tier: fe  
spec:
   strategy:
   replicas: 3
   selector:
      matchLabels:
         app: web
   template:
      metadata:
         name: app 
         labels:
            app: web  
      spec:
         containers:
         - name: app 
           image: mylandmarktech/hello   
           ports: 
           - containerPort: 80 

Deployments  :
    strategy [ReCreate and RollingUpdates]
    techniques [Blue/Green, Canary]

Resource, requests and limits:
--------------------------
--------------------------
Requests and limits are the mechanisms Kubernetes uses to control resources
such as CPU and memory. 
Requests are what the container is guaranteed to get. 
If a container requests a resource, 
Kubernetes will only schedule it on a node that can give it that resource.

Limits, on the other hand, make sure a container never goes above a certain value. 
The container is only allowed to go up to the limit, and then it is restricted.

Resoruce request:
---------------
A request is the amount of that resources that the system 
will guarantee for the container, and Kubernetes will use this value 
to decide on which node to place the pod. 

Resource Limit:
A limit is the maximum amount of resources that 
Kubernetes will allow the container to use.

Cluster = node1[mem=4000Mi/32Mi]    cpu[8000m/4000m]     :
          node2[mem=4000Mi/2200Mi]  cpu[16000m/12000m]
          node11[mem=4000Mi/2200Mi] cpu[16000m/12000m]
pod2.yml -- nodes/pods  
========
apiVersion: v1
kind: Pod
metadata: 
  name: javawebapp   
spec:
  containers:
  - name: javawebapp 
    image: mylandmarktech/java-web-app   
    ports:
    - containerPort: 8080   
    resources:
      requests:
        memory: "128Mi"
        cpu: "500m"          
      limits:
        memory: "512Mi"
        cpu: "1000m"

kubectl top pods  
kubectl top nodes   


Horizontal Pod AutoScaling  - HPA  :
==================================
POD AutoScaling --> Kuberenets POD AutoScaling Will make sure u have minimum number 
pod replicas available at any time & based on the observed CPU/Memory utilization
on pods it can scale PODS.
HPA Will Scale up/down pod replicas of Deployment/ReplicaSet/ReplicationController 
based on observerd CPU & Memory utilization base the target specified. 

What is difference b/w Kubernetes AutoScaling(POD AutoScaling) & AWS AutoScaling?


  aws  
  AutoScaling Group = ASG
     minimum   10      20 [81%]  21
     desired   10      20 [75%]
     maximum   100 

  ScalingPolicy:
     memory utilization
       cpu -gt 80% 
       cpu -lt 40%     
     cpu utilization
difference b/w Kubernetes AutoScaling(POD AutoScaling) 
                   & AWS AutoScaling?

app2.yml  
=======
kind: Deployment
apiVersion: apps/v1
metadata:
  name: webapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: tesla
  template:
    metadata:
      name: webapp
      labels:
        app: tesla
    spec:
      containers:
      - name: app
        image: mylandmarktech/maven-web-app
        resources:
          requests:
            cpu: "1000"
            memory: "256Mi"
          limits:
            cpu: "1000"
            memory: "256Mi"
        ports:
        - containerPort: 8080

error: Metrics API not available
    kubernetes addons/plugins:
      Metrics Server

Configure a Metrics Server on our Cluster4??
===========================================
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml


wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml


https://github.com/LandmakTechnology/metric-server
git clone https://github.com/LandmakTechnology/metric-server
kubectl apply -f metric-server/metrics-server-deploy.yml
=====================================================
ubuntu@master:~/tesla$ kubectl apply -f metric-server/metrics-server-deploy.yml
serviceaccount/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
service/metrics-server created
deployment.apps/metrics-server created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
ubuntu@master:~/tesla$

metrics-server:
  nodes  
  pods 

RBAC objects:
  serviceaccount metrics-server 
     - user  
     - groups 
     - pods     
  clusterrole
     - pods/nodes [get/watch/list] 
  clusterrolebinding
     - 
  rolebinding

Deployment with HPA
==================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hpadeployment
spec:
  replicas: 2
  selector:
    matchLabels:
      name: hpapod
  template:
    metadata:
      labels:
        name: hpapod
    spec:
      containers:
        - name: hpacontainer
          image: k8s.gcr.io/hpa-example
          ports:
          - name: http
            containerPort: 80
          resources:
            requests:
              cpu: "100m"
              memory: "64Mi"
            limits:
              cpu: "100m"
              memory: "256Mi"
---
apiVersion: autoscaling/v2 
kind: HorizontalPodAutoscaler  
metadata:
  name: hpadeploymentautoscaler 
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment 
    name: hpadeployment
  minReplicas: 2
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 40
  - type: Resource
    resource:
     name: memory
     target:
      type: Utilization
      averageUtilization: 40
---
apiVersion: v1
kind: Service
metadata:
  name: hpaclusterservice
  labels:
    name: hpaservice
spec:
  ports:
    - port: 80
      targetPort: 80
  selector:
    name: hpapod
  type: ClusterIP

-# Create temp POD using below command interatively and increase the 
-# load on demo app by accessing the service.

kubectl run -i --tty load-generator --rm  --image=busybox /bin/sh

-# Access the service to increase the load.

while true; do wget -q -O- http://hpaclusterservice; done  

-# Java Web Appliction With HPA
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  selector:
    matchLabels:
      app: javawebapp
  template:
    metadata:
      name: javawebapppod
      labels:
        app: javawebapp
    spec:
      containers:
      - name: myapp
        image: mylandmarktech/java-web-app
        ports:
        - containerPort: 8080
        resources:
          requests:
            cpu: 300m
            memory: 256Mi
          limits:
            cpu: 400m
            memory: 512Mi

Vertical Pod AutoScaling : 
Horizontal Pod AutoScaling  :
Cluster AutoScaling:

https://github.com/LandmakTechnology/spring-boot-docker
-# Spring App & Mongod DB as POD without volumes
Stateless applications deployment:
  Use deployment as the choice kubernetes object  
  ReplicaSets/ReplicationController:  

mongo database:
===============
  use StatefulSets as the choice kubernetes object for Stateful  
  application deployments   
  ReplicaSets/ReplicationController/deployment

Stateless
--- springapp.yml/
    springapp-deployment.yml   
    springapp-svc.yml  
    secret.yml 
    configMap.yml       

Stateful
--- mongo.yml/
    mongo-rs.yml  or  mongo-statefulset.yml / 
    mongo-svc.yml 
    persistenvolume.yml  
    persistenvolumeclaim.yml
    secret.yml 
    configMap.yml       
---

  mongodb:
      host: ${MONGO_DB_HOSTNAME}
      port: 27017
      username: ${MONGO_DB_USERNAME}
      password: ${MONGO_DB_PASSWORD}
      database: users
      authentication-database: admin
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: springapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: springapp
  template:
    metadata:
      labels:
        app: springapp
    spec:
      containers:
      - name: springappcontainer
        image: mylandmarktech/spring-boot-mongo
        ports:
        - containerPort: 8080
        env:
        - name: MONGO_DB_HOSTNAME
          value:  mongosvc
        - name: MONGO_DB_USERNAME
          value: devdb
        - name: MONGO_DB_PASSWORD
          value: devdb@123
        resources:
          requests:
            cpu: 200m
            memory: 256Mi
          limits:
            memory: "512Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: springappsvc
spec:
  type: NodePort
  selector:
    app: springapp
  ports:
  - port: 80
    targetPort: 8080

appsvc---pod:8080   
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: mongodb
spec:
  selector:
    matchLabels:
      app: mongo
  template:
    metadata:
      name: myapp
      labels:
        app: mongo
    spec:
      containers:
      - name: mongodbcontainer
        image: mongo
        ports:
        - containerPort: 27017
        env:
        - name: MONGO_INITDB_ROOT_USERNAME
          value: devdb
        - name: MONGO_INITDB_ROOT_PASSWORD
          value: devdb@123
---
apiVersion: v1
kind: Service
metadata:
  name: mongosvc
spec:
  type: ClusterIP
  selector:
    app: mongo
  ports:
  - port: 27017
    targetPort: 27017

Kubernetes volumes:
==================    = kubernetes 9 and 10  




















